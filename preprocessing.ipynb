{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6a3acee6-ec4d-43d0-9095-63ac51d0b7ac",
      "metadata": {
        "id": "6a3acee6-ec4d-43d0-9095-63ac51d0b7ac"
      },
      "source": [
        "# Setup Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ccf632a1-94ce-4c05-bef3-0ce50514ff9e",
      "metadata": {
        "id": "ccf632a1-94ce-4c05-bef3-0ce50514ff9e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# NumPy is used for numerical operations (arrays, math functions, etc.)\n",
        "\n",
        "import pandas as pd\n",
        "# Pandas is used to load, inspect, clean, and manipulate tabular datasets (DataFrames)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Used to split the dataset into training and testing sets\n",
        "# This helps us evaluate model performance on unseen data\n",
        "\n",
        "\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "# SimpleImputer: fills missing values using strategies like mean, median, mode, or constant\n",
        "# KNNImputer: fills missing values using nearest neighbors (more advanced imputation)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler,    # Standardizes features (mean=0, std=1)\n",
        "    MinMaxScaler,      # Scales features to a fixed range (usually 0 to 1)\n",
        "    RobustScaler,      # Scales using median and IQR (robust to outliers)\n",
        "    MaxAbsScaler,      # Scales by maximum absolute value (good for sparse data)\n",
        "    Normalizer         # Normalizes each row to unit length (more common in text/vector data)\n",
        ")\n",
        "# These are all feature scaling techniques used before training ML models\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "# OneHotEncoder: converts categorical variables into binary (0/1) columns\n",
        "# OrdinalEncoder: converts categories into integer labels\n",
        "\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# Allows us to apply different preprocessing steps to different column types\n",
        "# (e.g., scaling numeric columns and encoding categorical columns)\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "# Chains preprocessing steps and the ML model together\n",
        "# Ensures consistent and leakage-free workflow\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "# LinearRegression: used for predicting continuous values (e.g., house prices)\n",
        "# LogisticRegression: used for binary classification (e.g., HighPrice = 0 or 1)\n",
        "\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    r2_score,               # Measures regression performance (explained variance)\n",
        "    mean_squared_error,     # Measures regression error magnitude\n",
        "    accuracy_score,         # Measures classification accuracy\n",
        "    classification_report   # Provides precision, recall, F1-score\n",
        ")\n",
        "# These help evaluate model performance\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "# Used to create clean and OS-independent file paths (better than hardcoding strings)\n",
        "\n",
        "\n",
        "import joblib\n",
        "# Used to save and load trained models or preprocessing pipelines\n",
        "# Important for deployment and reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting your google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8SRV96i93O-",
        "outputId": "528deab7-a742-4ba0-d1f2-a7075ef69fc5"
      },
      "id": "j8SRV96i93O-",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Overview: House Prices – Advanced Regression Techniques\n",
        "For this preprocessing demonstration, we are using the House Prices – Advanced Regression Techniques dataset from Kaggle.\n",
        "\n",
        "**Dataset Link:**\n",
        "https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques\n",
        "\n",
        "This dataset is based on the Ames Housing dataset, which includes detailed information about residential homes in Ames, Iowa.\n",
        "\n",
        "**It contains:**\n",
        "\n",
        "- Numeric features (e.g., LotArea, YearBuilt, TotalBsmtSF)\n",
        "\n",
        "- Categorical features (e.g., Neighborhood, HouseStyle, GarageType)\n",
        "\n",
        "- Missing values (useful for demonstrating imputation)\n",
        "\n",
        "- Target variable: SalePrice (continuous variable)\n",
        "\n",
        "\n",
        "**Why We Chose This Dataset**\n",
        "\n",
        "This dataset is ideal for demonstrating preprocessing techniques because:\n",
        "\n",
        "- It contains both numeric and categorical variables\n",
        "\n",
        "- It includes missing values\n",
        "\n",
        "- It allows us to demonstrate scaling and encoding\n",
        "\n",
        "- It is realistic and slightly messy (like real-world data)\n",
        "\n",
        "**ML Tasks in This Notebook**\n",
        "\n",
        "**We use this dataset for:**\n",
        "\n",
        "- Linear Regression → Predicting SalePrice\n",
        "\n",
        "- Logistic Regression → Predicting HighPrice\n",
        "(a binary variable created based on whether the house price is above the median)\n",
        "\n",
        "This allows us to demonstrate preprocessing techniques for both regression and classification using the same dataset."
      ],
      "metadata": {
        "id": "MiMKeYLC5BPU"
      },
      "id": "MiMKeYLC5BPU"
    },
    {
      "cell_type": "markdown",
      "id": "2d08dce8-338e-4095-a0e1-7a4cb0beb57f",
      "metadata": {
        "id": "2d08dce8-338e-4095-a0e1-7a4cb0beb57f"
      },
      "source": [
        "# 1) Load Kaggle House Prices dataset (train.csv)\n",
        "\n",
        "We first load the dataset into a pandas DataFrame called df. This is the raw “table” we will inspect and clean before training ML models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "400d9ce0-dd1f-42dd-ad95-1c0651026dd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "400d9ce0-dd1f-42dd-ad95-1c0651026dd1",
        "outputId": "3a6a0fa7-014a-4007-b549-560a4a79f586"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50ecbe44-58fe-4c93-8f32-425c951b1045\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50ecbe44-58fe-4c93-8f32-425c951b1045')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50ecbe44-58fe-4c93-8f32-425c951b1045 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50ecbe44-58fe-4c93-8f32-425c951b1045');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Create a path object pointing to the dataset\n",
        "data_path = Path(\"/content/drive/MyDrive/ML/train.csv\") # --> customize the path according to your folder structure here\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Quick preview\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "df.head() is used to just get a quick preview of the dataset.\n",
        "\n",
        "By default, it will show only the first five rows in the dataset. If you wish to see more rows for a better understanding, you can pass the number of rows you want to see as a parameter inside the function.\n",
        "\n",
        "**Eg.:** df.head(10) --> this will show the first ten rows"
      ],
      "metadata": {
        "id": "2z5bjoQy6NSu"
      },
      "id": "2z5bjoQy6NSu"
    },
    {
      "cell_type": "markdown",
      "id": "d4f0e059-f2bf-48b6-82cf-20b9b92c13fb",
      "metadata": {
        "id": "d4f0e059-f2bf-48b6-82cf-20b9b92c13fb"
      },
      "source": [
        "# 2) Keep a subset of columns\n",
        "\n",
        "The original dataset has many columns. To make things easy, we keep a smaller set that still includes both numeric and categorical features (and missing values), so we can demonstrate all preprocessing steps clearly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fc4f8cb1-37fa-4927-8996-c7d046318c1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fc4f8cb1-37fa-4927-8996-c7d046318c1a",
        "outputId": "eb7f04a1-41aa-4a4e-fadf-1c29119913bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SalePrice  LotArea  LotFrontage  OverallQual  YearBuilt  TotalBsmtSF  \\\n",
              "0     208500     8450         65.0            7       2003          856   \n",
              "1     181500     9600         80.0            6       1976         1262   \n",
              "2     223500    11250         68.0            7       2001          920   \n",
              "3     140000     9550         60.0            7       1915          756   \n",
              "4     250000    14260         84.0            8       2000         1145   \n",
              "\n",
              "  Neighborhood HouseStyle GarageType MSZoning  \n",
              "0      CollgCr     2Story     Attchd       RL  \n",
              "1      Veenker     1Story     Attchd       RL  \n",
              "2      CollgCr     2Story     Attchd       RL  \n",
              "3      Crawfor     2Story     Detchd       RL  \n",
              "4      NoRidge     2Story     Attchd       RL  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68838afe-28d6-4bae-ac06-f21868bf7daf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>MSZoning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>208500</td>\n",
              "      <td>8450</td>\n",
              "      <td>65.0</td>\n",
              "      <td>7</td>\n",
              "      <td>2003</td>\n",
              "      <td>856</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>181500</td>\n",
              "      <td>9600</td>\n",
              "      <td>80.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1976</td>\n",
              "      <td>1262</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>1Story</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>223500</td>\n",
              "      <td>11250</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7</td>\n",
              "      <td>2001</td>\n",
              "      <td>920</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>140000</td>\n",
              "      <td>9550</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1915</td>\n",
              "      <td>756</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>250000</td>\n",
              "      <td>14260</td>\n",
              "      <td>84.0</td>\n",
              "      <td>8</td>\n",
              "      <td>2000</td>\n",
              "      <td>1145</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68838afe-28d6-4bae-ac06-f21868bf7daf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68838afe-28d6-4bae-ac06-f21868bf7daf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68838afe-28d6-4bae-ac06-f21868bf7daf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1460,\n  \"fields\": [\n    {\n      \"column\": \"SalePrice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79442,\n        \"min\": 34900,\n        \"max\": 755000,\n        \"num_unique_values\": 663,\n        \"samples\": [\n          91300,\n          174500,\n          150900\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LotArea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9981,\n        \"min\": 1300,\n        \"max\": 215245,\n        \"num_unique_values\": 1073,\n        \"samples\": [\n          10186,\n          8163,\n          8854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LotFrontage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.284751774483183,\n        \"min\": 21.0,\n        \"max\": 313.0,\n        \"num_unique_values\": 110,\n        \"samples\": [\n          150.0,\n          91.0,\n          84.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OverallQual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1,\n          6,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YearBuilt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 1872,\n        \"max\": 2010,\n        \"num_unique_values\": 112,\n        \"samples\": [\n          1999,\n          1936,\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalBsmtSF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 438,\n        \"min\": 0,\n        \"max\": 6110,\n        \"num_unique_values\": 721,\n        \"samples\": [\n          1536,\n          1192,\n          684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neighborhood\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"BrkSide\",\n          \"Timber\",\n          \"CollgCr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HouseStyle\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"1Story\",\n          \"SLvl\",\n          \"2Story\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GarageType\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Attchd\",\n          \"Detchd\",\n          \"2Types\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSZoning\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"RM\",\n          \"RH\",\n          \"C (all)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "cols = [\n",
        "    \"SalePrice\",          # Target variable for regression (continuous output)\n",
        "    \"LotArea\",            # Numeric feature (lot size in square feet)\n",
        "    \"LotFrontage\",        # Numeric feature with missing values\n",
        "    \"OverallQual\",        # Numeric feature representing overall material/finish quality (ordinal-like)\n",
        "    \"YearBuilt\",          # Numeric feature (year the house was built)\n",
        "    \"TotalBsmtSF\",        # Numeric feature (total basement area in square feet)\n",
        "    \"Neighborhood\",       # Categorical feature (location of the house)\n",
        "    \"HouseStyle\",         # Categorical feature (type/style of house)\n",
        "    \"GarageType\",         # Categorical feature with missing values\n",
        "    \"MSZoning\"            # Categorical feature with missing values\n",
        "]\n",
        "\n",
        "df = df[cols].copy()\n",
        "# We create an independent copy of only the selected columns. Using .copy()\n",
        "# prevents SettingWithCopyWarning and ensures modifications to this DataFrame do not affect the original one.\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d697b8-f365-4dec-a4c8-c7daec8cfec3",
      "metadata": {
        "id": "48d697b8-f365-4dec-a4c8-c7daec8cfec3"
      },
      "source": [
        "# 3) Create targets for Linear and Logistic Regression\n",
        "\n",
        "For Linear Regression, we predict the actual **SalePrice**. For Logistic Regression, we create a simple yes/no label called **HighPrice** based on whether a house is above the median price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "af3982cb-caf4-4711-98a3-234c06cd27d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "af3982cb-caf4-4711-98a3-234c06cd27d7",
        "outputId": "22322b9d-3ee4-4b39-c639-fa01a2113d40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SalePrice  HighPrice\n",
              "0     208500          1\n",
              "1     181500          1\n",
              "2     223500          1\n",
              "3     140000          0\n",
              "4     250000          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10c4e7c7-d0ed-4d14-afc3-406d557c8e01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>HighPrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>208500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>181500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>223500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>140000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>250000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10c4e7c7-d0ed-4d14-afc3-406d557c8e01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-10c4e7c7-d0ed-4d14-afc3-406d557c8e01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-10c4e7c7-d0ed-4d14-afc3-406d557c8e01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[[\\\"SalePrice\\\", \\\"HighPrice\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"SalePrice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42024,\n        \"min\": 140000,\n        \"max\": 250000,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          181500,\n          250000,\n          223500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HighPrice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Create a new binary target variable column called \"HighPrice\".\n",
        "# If a house's SalePrice is greater than the median SalePrice, assign 1.\n",
        "# Otherwise, assign 0.\n",
        "# This converts a continuous regression target into a classification target.\n",
        "\n",
        "df[\"HighPrice\"] = (df[\"SalePrice\"] > df[\"SalePrice\"].median()).astype(int)\n",
        "\n",
        "\n",
        "# Display the original SalePrice and the new HighPrice column\n",
        "# to verify that the binary transformation was created correctly.\n",
        "\n",
        "df[[\"SalePrice\", \"HighPrice\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "**astype(int)** converts the data type of a column into integers.\n",
        "\n",
        "In this case, the comparison: **df[\"SalePrice\"] > df[\"SalePrice\"].median()** produces Boolean values:\n",
        "- True → price is above the median\n",
        "\n",
        "- False → price is below or equal to the median\n",
        "\n",
        "Machine learning models typically require numeric inputs, not Boolean values.\n",
        "So:\n",
        "\n",
        "- True becomes 1\n",
        "\n",
        "- False becomes 0\n",
        "\n",
        "This converts the logical condition into a proper numeric binary target suitable for classification models like Logistic Regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "D4lKnTiD8q4S"
      },
      "id": "D4lKnTiD8q4S"
    },
    {
      "cell_type": "markdown",
      "id": "bd9febe7-c059-4c16-a541-8081ce266503",
      "metadata": {
        "id": "bd9febe7-c059-4c16-a541-8081ce266503"
      },
      "source": [
        "# 4) Split features (X) and targets (y)\n",
        "\n",
        "We separate inputs (features) from outputs (targets). Models learn patterns from X to predict y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ffcaceb6-fc6d-4c8e-b0ea-7d894ec88bf3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ffcaceb6-fc6d-4c8e-b0ea-7d894ec88bf3",
        "outputId": "04b3f205-b029-4139-f7e6-ef9053c8e421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LotArea  LotFrontage  OverallQual  YearBuilt  TotalBsmtSF Neighborhood  \\\n",
              "0     8450         65.0            7       2003          856      CollgCr   \n",
              "1     9600         80.0            6       1976         1262      Veenker   \n",
              "2    11250         68.0            7       2001          920      CollgCr   \n",
              "3     9550         60.0            7       1915          756      Crawfor   \n",
              "4    14260         84.0            8       2000         1145      NoRidge   \n",
              "\n",
              "  HouseStyle GarageType MSZoning  \n",
              "0     2Story     Attchd       RL  \n",
              "1     1Story     Attchd       RL  \n",
              "2     2Story     Attchd       RL  \n",
              "3     2Story     Detchd       RL  \n",
              "4     2Story     Attchd       RL  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bab840b4-9513-4f3c-8ecc-52658e7b9116\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>MSZoning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8450</td>\n",
              "      <td>65.0</td>\n",
              "      <td>7</td>\n",
              "      <td>2003</td>\n",
              "      <td>856</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9600</td>\n",
              "      <td>80.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1976</td>\n",
              "      <td>1262</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>1Story</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11250</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7</td>\n",
              "      <td>2001</td>\n",
              "      <td>920</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9550</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1915</td>\n",
              "      <td>756</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14260</td>\n",
              "      <td>84.0</td>\n",
              "      <td>8</td>\n",
              "      <td>2000</td>\n",
              "      <td>1145</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bab840b4-9513-4f3c-8ecc-52658e7b9116')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bab840b4-9513-4f3c-8ecc-52658e7b9116 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bab840b4-9513-4f3c-8ecc-52658e7b9116');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 1460,\n  \"fields\": [\n    {\n      \"column\": \"LotArea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9981,\n        \"min\": 1300,\n        \"max\": 215245,\n        \"num_unique_values\": 1073,\n        \"samples\": [\n          10186,\n          8163,\n          8854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LotFrontage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.284751774483183,\n        \"min\": 21.0,\n        \"max\": 313.0,\n        \"num_unique_values\": 110,\n        \"samples\": [\n          150.0,\n          91.0,\n          84.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OverallQual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1,\n          6,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YearBuilt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 1872,\n        \"max\": 2010,\n        \"num_unique_values\": 112,\n        \"samples\": [\n          1999,\n          1936,\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalBsmtSF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 438,\n        \"min\": 0,\n        \"max\": 6110,\n        \"num_unique_values\": 721,\n        \"samples\": [\n          1536,\n          1192,\n          684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neighborhood\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"BrkSide\",\n          \"Timber\",\n          \"CollgCr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HouseStyle\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"1Story\",\n          \"SLvl\",\n          \"2Story\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GarageType\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Attchd\",\n          \"Detchd\",\n          \"2Types\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSZoning\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"RM\",\n          \"RH\",\n          \"C (all)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Create the feature matrix by removing the target variables.\n",
        "# X contains only the input variables that will be used to train the models.\n",
        "\n",
        "X = df.drop(columns=[\"SalePrice\", \"HighPrice\"])\n",
        "\n",
        "# Define the regression target variable.\n",
        "# This will be used for predicting continuous house prices (Linear Regression).\n",
        "\n",
        "y_reg = df[\"SalePrice\"]\n",
        "\n",
        "# Define the classification target variable.\n",
        "# This will be used for predicting whether a house is high-priced (Logistic Regression).\n",
        "\n",
        "y_clf = df[\"HighPrice\"]\n",
        "\n",
        "\n",
        "# Display the first few rows of the feature matrix\n",
        "# to verify that target variables have been removed correctly.\n",
        "\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "The **drop()** function is used to remove rows or columns from a dataset.\n",
        "\n",
        "In this case, it is used to remove specific columns so they are not included in the feature matrix.\n",
        "\n",
        "The columns parameter tells the function which columns should be removed.\n",
        "\n",
        "- If you want to remove multiple columns, pass them as a list.\n",
        "\n",
        "- If you want to remove only one column, you can pass just the column name as a string"
      ],
      "metadata": {
        "id": "O3eQSIap_XyK"
      },
      "id": "O3eQSIap_XyK"
    },
    {
      "cell_type": "markdown",
      "id": "3d2a96f7-4ed6-4fff-b724-6c2e67da52a6",
      "metadata": {
        "id": "3d2a96f7-4ed6-4fff-b724-6c2e67da52a6"
      },
      "source": [
        "# **A) Missing values: detection + handling**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b480b588-222b-4d94-9c7d-6c9c3790d88d",
      "metadata": {
        "id": "b480b588-222b-4d94-9c7d-6c9c3790d88d"
      },
      "source": [
        "## A1) df.isna() — see missing values (True/False)\n",
        "\n",
        "This shows where values are missing. True means “this cell is empty/NA” and False means it has data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a160df50-acee-4206-a69f-68666cac4a66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "a160df50-acee-4206-a69f-68666cac4a66",
        "outputId": "7cd958d0-cb2b-4f5d-bf5d-1bf74d61caa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LotArea  LotFrontage  OverallQual  YearBuilt  TotalBsmtSF  Neighborhood  \\\n",
              "0    False        False        False      False        False         False   \n",
              "1    False        False        False      False        False         False   \n",
              "2    False        False        False      False        False         False   \n",
              "3    False        False        False      False        False         False   \n",
              "4    False        False        False      False        False         False   \n",
              "5    False        False        False      False        False         False   \n",
              "6    False        False        False      False        False         False   \n",
              "7    False         True        False      False        False         False   \n",
              "8    False        False        False      False        False         False   \n",
              "9    False        False        False      False        False         False   \n",
              "\n",
              "   HouseStyle  GarageType  MSZoning  \n",
              "0       False       False     False  \n",
              "1       False       False     False  \n",
              "2       False       False     False  \n",
              "3       False       False     False  \n",
              "4       False       False     False  \n",
              "5       False       False     False  \n",
              "6       False       False     False  \n",
              "7       False       False     False  \n",
              "8       False       False     False  \n",
              "9       False       False     False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-604704c0-ba7a-4a80-b668-8db5ecf31c3a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>MSZoning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-604704c0-ba7a-4a80-b668-8db5ecf31c3a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-604704c0-ba7a-4a80-b668-8db5ecf31c3a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-604704c0-ba7a-4a80-b668-8db5ecf31c3a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"LotArea\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LotFrontage\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OverallQual\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YearBuilt\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalBsmtSF\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neighborhood\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HouseStyle\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GarageType\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSZoning\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# First, check for missing values in the dataset using isna().\n",
        "# Then, head(10) displays the first 10 rows so we can visually inspect where missing values occur.\n",
        "# This is an example of function chaining: The output of isna() becomes the input to head().\n",
        "\n",
        "X.isna().head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "**isna()** checks each cell in the dataset and identifies whether it contains a missing value.\n",
        "\n",
        "It returns:\n",
        "\n",
        "- True if the value is missing (NaN)\n",
        "\n",
        "- False if the value is present\n",
        "\n",
        "It does not modify the data — it simply helps detect where missing values exist so they can be handled properly."
      ],
      "metadata": {
        "id": "I5QCrxByAh53"
      },
      "id": "I5QCrxByAh53"
    },
    {
      "cell_type": "markdown",
      "id": "fe965936-1f9d-4bf1-9645-fe7747b7b4d3",
      "metadata": {
        "id": "fe965936-1f9d-4bf1-9645-fe7747b7b4d3"
      },
      "source": [
        "## A2) df.isna().sum() — missing values per column\n",
        "\n",
        "This counts how many missing values each column has. It helps you decide where you need to clean or impute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fd92548b-36c3-40a4-813b-caa332cb56b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "fd92548b-36c3-40a4-813b-caa332cb56b2",
        "outputId": "95b8e282-ae0c-4b9a-a309-a234b3c94006"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LotArea           0\n",
              "LotFrontage     259\n",
              "OverallQual       0\n",
              "YearBuilt         0\n",
              "TotalBsmtSF       0\n",
              "Neighborhood      0\n",
              "HouseStyle        0\n",
              "GarageType       81\n",
              "MSZoning          0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LotArea</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OverallQual</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YearBuilt</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neighborhood</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HouseStyle</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageType</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSZoning</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Check the total number of missing values in each column.\n",
        "# sum() adds up the True values in each column.\n",
        "# Since True is treated as 1 and False as 0,\n",
        "# the result shows how many missing values each column contains.\n",
        "\n",
        "X.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "isna() → identifies missing values\n",
        "\n",
        "sum() → counts them\n",
        "\n",
        "Result → number of missing entries per column\n",
        "\n",
        "This is one of the most common first checks in preprocessing before building ML models."
      ],
      "metadata": {
        "id": "-Rb2my6OBbOF"
      },
      "id": "-Rb2my6OBbOF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A3) df.isna().sum(axis=1) — missing values per row\n",
        "This counts missing values per row (per house). It helps identify rows that are “too incomplete” and might be removed."
      ],
      "metadata": {
        "id": "rL_mrgmfyt5w"
      },
      "id": "rL_mrgmfyt5w"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: isna() identifies missing values in every cell (True = missing, False = present).\n",
        "# Step 2: sum(axis=1) adds across columns for each row.\n",
        "#         axis=1 means we are summing horizontally (row-wise).\n",
        "#\n",
        "# This tells us how many missing values each individual sample (house)\n",
        "\n",
        "X.isna().sum(axis=1).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "FHYPoWFUyz7g",
        "outputId": "dfe44e63-1e0b-4425-cdbc-e1bfd39d2a98"
      },
      "id": "FHYPoWFUyz7g",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "5    0\n",
              "6    0\n",
              "7    1\n",
              "8    0\n",
              "9    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A4) df.dropna() — drop rows that contain any missing value\n",
        "This removes any row that has at least one missing value. It’s simple, but you can lose a lot of data"
      ],
      "metadata": {
        "id": "RxQ1h-dJy1ip"
      },
      "id": "RxQ1h-dJy1ip"
    },
    {
      "cell_type": "code",
      "source": [
        "# dropna() deletes any row where one or more columns have missing data.\n",
        "# This is a simple way to clean data, but it can reduce the dataset size significantly.\n",
        "#\n",
        "# We then compare the original shape with the new shape\n",
        "# to see how many rows were removed.\n",
        "# .shape returns (number_of_rows, number_of_columns).\n",
        "\n",
        "X_drop_rows = X.dropna()\n",
        "(X.shape, X_drop_rows.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4iyuhply8k3",
        "outputId": "c00f70b6-dcc9-4fc8-a944-394a0670ba73"
      },
      "id": "Z4iyuhply8k3",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1460, 9), (1127, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A5) df.dropna(axis=1) — drop columns that contain any missing value\n",
        "This removes columns that have missing values. It’s easy, but you might accidentally delete important features."
      ],
      "metadata": {
        "id": "DBLGNDDCzD8E"
      },
      "id": "DBLGNDDCzD8E"
    },
    {
      "cell_type": "code",
      "source": [
        "# dropna(axis=1) deletes columns instead of rows.\n",
        "# axis=1 means the operation is performed column-wise.\n",
        "#\n",
        "# This keeps only columns that have no missing values at all.\n",
        "# While simple, this approach can remove important features.\n",
        "#\n",
        "# We compare the original shape with the new shape\n",
        "# and also display the remaining column names\n",
        "# to see which features were retained.\n",
        "\n",
        "X_drop_cols = X.dropna(axis=1)\n",
        "(X.shape, X_drop_cols.shape, X_drop_cols.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBzXkTI5zGy4",
        "outputId": "55dfec68-339e-4c00-ce7d-5d6e086c54c1"
      },
      "id": "QBzXkTI5zGy4",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1460, 9),\n",
              " (1460, 7),\n",
              " Index(['LotArea', 'OverallQual', 'YearBuilt', 'TotalBsmtSF', 'Neighborhood',\n",
              "        'HouseStyle', 'MSZoning'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A6) df.dropna(subset=[...]) — drop rows only if specific columns are missing\n",
        "Sometimes only certain columns are critical. This drops rows only when the value in those particular columns are missing."
      ],
      "metadata": {
        "id": "LeWyBJFezIxN"
      },
      "id": "LeWyBJFezIxN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows only if specific columns contain missing values.\n",
        "#\n",
        "# The subset parameter allows us to specify which columns\n",
        "# should be checked for missing values.\n",
        "# In this case, rows will be removed only if\n",
        "# \"LotFrontage\" or \"GarageType\" is missing.\n",
        "#\n",
        "# Other columns are ignored when deciding whether to drop the row.\n",
        "# This is useful when only certain features are considered critical.\n",
        "#\n",
        "# We compare the original shape with the new shape\n",
        "# to see how many rows were removed.\n",
        "\n",
        "X_drop_subset = X.dropna(subset=[\"LotFrontage\", \"GarageType\"])\n",
        "(X.shape, X_drop_subset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzqWl2OrzSry",
        "outputId": "3f72496d-3e7d-455b-e2c0-907537c14c78"
      },
      "id": "GzqWl2OrzSry",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1460, 9), (1127, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A7) df.fillna(value) — fill all missing values with one constant\n",
        "This replaces missing values with a single constant. It’s fast and sometimes useful (like filling missing categories with \"Missing\")."
      ],
      "metadata": {
        "id": "WKvmvL3vzVGR"
      },
      "id": "WKvmvL3vzVGR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace all missing values in the dataset with a constant value.\n",
        "#\n",
        "# fillna(\"Missing\") tells the dataset to replace every missing entry\n",
        "# with the string \"Missing\".\n",
        "# You can chose to replace it with any other value.\n",
        "\n",
        "# After filling, we check again for missing values using isna().sum()\n",
        "# to confirm that no missing values remain.\n",
        "\n",
        "X_fill_const = X.fillna(\"Missing\")\n",
        "X_fill_const.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "6zPPs_H1zbPR",
        "outputId": "6875d7de-2330-4376-c668-17ae98015161"
      },
      "id": "6zPPs_H1zbPR",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LotArea         0\n",
              "LotFrontage     0\n",
              "OverallQual     0\n",
              "YearBuilt       0\n",
              "TotalBsmtSF     0\n",
              "Neighborhood    0\n",
              "HouseStyle      0\n",
              "GarageType      0\n",
              "MSZoning        0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LotArea</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OverallQual</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YearBuilt</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neighborhood</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HouseStyle</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageType</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSZoning</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A8) df[col].fillna(df[col].mean()) — mean imputation (one column)\n",
        "If a numeric column has missing values, replacing them with the column’s average is a common quick fix."
      ],
      "metadata": {
        "id": "zMbsB0pfzd7U"
      },
      "id": "zMbsB0pfzd7U"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a separate copy of the dataset so the original data remains unchanged.\n",
        "#\n",
        "# Replace missing values in the \"LotFrontage\" column\n",
        "# with the mean (average) of the existing values in that column.\n",
        "#\n",
        "# When calculating the mean, missing values (NaN) are automatically ignored.\n",
        "# This means the average is computed only using the available (non-missing) values.\n",
        "#\n",
        "# This method is called mean imputation and assumes that\n",
        "# missing values can be reasonably approximated by the overall average.\n",
        "#\n",
        "# Finally, we check whether any missing values remain in the \"LotFrontage\" column.\n",
        "\n",
        "X_mean = X.copy()\n",
        "X_mean[\"LotFrontage\"] = X_mean[\"LotFrontage\"].fillna(X_mean[\"LotFrontage\"].mean())\n",
        "X_mean[\"LotFrontage\"].isna().sum()"
      ],
      "metadata": {
        "id": "ZveaEPpXzqo8"
      },
      "id": "ZveaEPpXzqo8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A9) df[col].fillna(df[col].median()) — median imputation (one column)\n",
        "Median is often safer than mean when there are outliers (very large/small values)."
      ],
      "metadata": {
        "id": "9i-8g_jSzvVE"
      },
      "id": "9i-8g_jSzvVE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a separate copy of the dataset so the original data remains unchanged.\n",
        "#\n",
        "# Replace missing values in the \"LotFrontage\" column\n",
        "# with the median (middle value) of the existing values in that column.\n",
        "#\n",
        "# The median is calculated using only the non-missing values.\n",
        "# Missing values (NaN) are automatically ignored during the calculation.\n",
        "#\n",
        "# Median imputation is often preferred when the data contains outliers,\n",
        "# because the median is less affected by extremely large or small values.\n",
        "#\n",
        "# Finally, we check whether any missing values remain in the \"LotFrontage\" column.\n",
        "\n",
        "X_median = X.copy()\n",
        "X_median[\"LotFrontage\"] = X_median[\"LotFrontage\"].fillna(X_median[\"LotFrontage\"].median())\n",
        "X_median[\"LotFrontage\"].isna().sum()\n"
      ],
      "metadata": {
        "id": "473cP4c3z0aA"
      },
      "id": "473cP4c3z0aA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A10) df[col].fillna(df[col].mode()[0]) — mode imputation (one column)\n",
        "Mode means “most common value.” This is often used for categorical columns."
      ],
      "metadata": {
        "id": "HfwOj-mPz8wK"
      },
      "id": "HfwOj-mPz8wK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a separate copy of the dataset so the original data remains unchanged.\n",
        "#\n",
        "# Replace missing values in the \"GarageType\" column\n",
        "# with the mode (the most frequently occurring value) of that column.\n",
        "#\n",
        "# mode() returns one or more values that appear most often.\n",
        "# Since it returns a collection, we select the first value using [0].\n",
        "#\n",
        "# Missing values (NaN) are automatically ignored when computing the mode.\n",
        "#\n",
        "# Mode imputation is commonly used for categorical features,\n",
        "# because replacing missing entries with the most common category\n",
        "# preserves the overall distribution reasonably well.\n",
        "#\n",
        "# Finally, we check whether any missing values remain in the \"GarageType\" column.\n",
        "\n",
        "X_mode = X.copy()\n",
        "X_mode[\"GarageType\"] = X_mode[\"GarageType\"].fillna(X_mode[\"GarageType\"].mode()[0])\n",
        "X_mode[\"GarageType\"].isna().sum()"
      ],
      "metadata": {
        "id": "24vMCAJg0Bfj"
      },
      "id": "24vMCAJg0Bfj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A11) SimpleImputer(strategy=\"mean\")\n",
        "SimpleImputer is the scikit-learn way to impute missing values. It’s better for ML because you can fit it on training data only, then reuse it on test data."
      ],
      "metadata": {
        "id": "NPJEfvxH0DPm"
      },
      "id": "NPJEfvxH0DPm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify all numeric columns in the dataset.\n",
        "#\n",
        "# select_dtypes(include=[np.number]) selects only columns that contain numeric data types.\n",
        "# .columns extracts just the column names from that selection.\n",
        "# This helps us apply numeric preprocessing only to numeric features.\n",
        "\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "\n",
        "# Create a SimpleImputer object with strategy=\"mean\".\n",
        "#\n",
        "# This means missing values in numeric columns\n",
        "# will be replaced with the column's mean (average).\n",
        "\n",
        "imp_mean = SimpleImputer(strategy=\"mean\")\n",
        "\n",
        "\n",
        "# Fit the imputer on the numeric columns and transform the data.\n",
        "# The result is returned as a NumPy array.\n",
        "\n",
        "X_num_imp_mean = imp_mean.fit_transform(X[numeric_cols])\n",
        "\n",
        "\n",
        "# Convert the transformed array back into a DataFrame\n",
        "# and restore the original column names for clarity.\n",
        "#\n",
        "# Since the display limit is set higher (e.g., vertical limit = 200),\n",
        "# more rows can be viewed without truncation.\n",
        "\n",
        "pd.DataFrame(X_num_imp_mean, columns=numeric_cols).head()\n"
      ],
      "metadata": {
        "id": "THT6ybYL0M1C"
      },
      "id": "THT6ybYL0M1C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Note**\n",
        "**select_dtypes(include=[np.number])**\n",
        "\n",
        "Selects only the numeric columns from the dataset.\n",
        "This ensures that numeric preprocessing (like mean imputation) is applied only to numerical features.\n",
        "\n",
        "**.columns**\n",
        "\n",
        "Extracts the column names from the selected subset.\n",
        "This allows us to reference those numeric columns later.\n",
        "\n",
        "**SimpleImputer(strategy=\"mean\")**\n",
        "\n",
        "Creates an imputation object that will replace missing values with the mean of each column.\n",
        "The mean is calculated using only the non-missing values.\n",
        "\n",
        "**fit_transform()**\n",
        "\n",
        "Performs two steps in one call:\n",
        "\n",
        "- fit() → learns the mean value of each numeric column\n",
        "\n",
        "- transform() → replaces missing values using those learned means\n",
        "\n",
        "It returns a NumPy array containing the imputed data.\n",
        "\n",
        "**pd.DataFrame(..., columns=...)**\n",
        "\n",
        "Converts the NumPy array back into a DataFrame and restores the original column names for clarity and readability."
      ],
      "metadata": {
        "id": "PS2cxchWB9wW"
      },
      "id": "PS2cxchWB9wW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A12) SimpleImputer(strategy=\"median\")\n",
        "Median imputation using scikit-learn works the same way, and is more robust to outliers."
      ],
      "metadata": {
        "id": "a0TmXdeY0ULk"
      },
      "id": "a0TmXdeY0ULk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SimpleImputer object with strategy=\"median\".\n",
        "#\n",
        "# This means missing values in numeric columns\n",
        "# will be replaced with the median (middle value) of each column.\n",
        "\n",
        "imp_median = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "# Fit the imputer on the numeric columns and transform the data.\n",
        "# The result is returned as a NumPy array.\n",
        "\n",
        "X_num_imp_median = imp_median.fit_transform(X[numeric_cols])\n",
        "\n",
        "# Convert the transformed array back into a DataFrame and restore the original column names for clarity.\n",
        "pd.DataFrame(X_num_imp_median, columns=numeric_cols).head()"
      ],
      "metadata": {
        "id": "g070tcKu0TX4"
      },
      "id": "g070tcKu0TX4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A13) SimpleImputer(strategy=\"most_frequent\")\n",
        "For categorical columns, filling missing values with the most common category is a typical approach."
      ],
      "metadata": {
        "id": "SOQxkwKm0hH2"
      },
      "id": "SOQxkwKm0hH2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify all categorical (non-numeric) columns in the dataset.\n",
        "\n",
        "cat_cols = X.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "\n",
        "# Create a SimpleImputer with strategy=\"most_frequent\".\n",
        "#\n",
        "# This means missing values will be replaced with the most frequently occurring value (mode) in each column.\n",
        "# This is commonly used for categorical features.\n",
        "\n",
        "imp_most = SimpleImputer(strategy=\"most_frequent\")\n",
        "\n",
        "\n",
        "# Fit the imputer on the categorical columns and transform the data.\n",
        "# The result is returned as a NumPy array.\n",
        "\n",
        "X_cat_imp_most = imp_most.fit_transform(X[cat_cols])\n",
        "\n",
        "\n",
        "# Convert the transformed array back into a DataFrame\n",
        "# and restore the original column names for clarity.\n",
        "\n",
        "pd.DataFrame(X_cat_imp_most, columns=cat_cols).head()\n"
      ],
      "metadata": {
        "id": "OY37jc5e2AjQ"
      },
      "id": "OY37jc5e2AjQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Note**\n",
        "\n",
        "**include vs exclude in select_dtypes()**\n",
        "\n",
        "include selects only the specified data types, while exclude removes the specified data types.\n",
        "\n",
        "include=[np.number] → keeps only numeric columns\n",
        "\n",
        "exclude=[np.number] → removes numeric columns and keeps non-numeric (categorical) columns\n",
        "\n",
        "We use this distinction to separate numeric and categorical features so that each type can be preprocessed appropriately."
      ],
      "metadata": {
        "id": "MaqgckAZECFy"
      },
      "id": "MaqgckAZECFy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A14) SimpleImputer(strategy=\"constant\")\n",
        "This replaces missing values with a constant like \"Missing\" for categories or 0 for numbers. It’s very explicit and easy to explain."
      ],
      "metadata": {
        "id": "xsJK5g8Q2CKw"
      },
      "id": "xsJK5g8Q2CKw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SimpleImputer with strategy=\"constant\".\n",
        "#\n",
        "# This means all missing values in the selected columns will be replaced with a fixed value.\n",
        "# Here, we set fill_value=\"Missing\", which inserts the string \"Missing\" wherever a value is absent.\n",
        "#\n",
        "# This approach is useful for categorical features,\n",
        "# where explicitly marking missing entries can preserve information.\n",
        "\n",
        "imp_const = SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")\n",
        "\n",
        "\n",
        "# Fit the imputer on the categorical columns and transform the data.\n",
        "#\n",
        "# fit_transform() first learns nothing from the data (since the value is constant),\n",
        "# and then replaces all missing values with the specified constant.\n",
        "#\n",
        "# The result is returned as a NumPy array.\n",
        "\n",
        "X_cat_imp_const = imp_const.fit_transform(X[cat_cols])\n",
        "\n",
        "\n",
        "# Convert the transformed array back into a DataFrame\n",
        "# and restore the original column names for readability.\n",
        "\n",
        "pd.DataFrame(X_cat_imp_const, columns=cat_cols).head()\n"
      ],
      "metadata": {
        "id": "e2q_1ZLX2GPk"
      },
      "id": "e2q_1ZLX2GPk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A15) KNNImputer()\n",
        "KNN imputation fills missing values by looking at “similar rows” (nearest neighbors). It can be more realistic, but it’s heavier than SimpleImputer."
      ],
      "metadata": {
        "id": "CkVXLbMU2H6H"
      },
      "id": "CkVXLbMU2H6H"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a KNNImputer object.\n",
        "#\n",
        "# KNNImputer fills missing values using the k-Nearest Neighbors approach.\n",
        "# n_neighbors=5 means that for each missing value,\n",
        "# the algorithm looks at the 5 most similar rows (based on other features)\n",
        "# and uses their values to estimate the missing one.\n",
        "\n",
        "knn_imp = KNNImputer(n_neighbors=5)\n",
        "\n",
        "\n",
        "# Fit the imputer on the numeric columns and transform the data.\n",
        "#\n",
        "# The result is returned as a NumPy array.\n",
        "\n",
        "X_num_knn = knn_imp.fit_transform(X[numeric_cols])\n",
        "\n",
        "\n",
        "# Convert the transformed array back into a DataFrame\n",
        "# and restore the original column names for clarity.\n",
        "\n",
        "pd.DataFrame(X_num_knn, columns=numeric_cols).head()\n"
      ],
      "metadata": {
        "id": "SWRYkDbL2MC8"
      },
      "id": "SWRYkDbL2MC8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Note**\n",
        "KNNImputer is not only for KNN models.\n",
        "\n",
        "It is a preprocessing technique and can be used before any machine learning model (Linear Regression, Logistic Regression, Random Forest, etc.).\n",
        "\n",
        "It works best with numeric data, because it relies on distance calculations between rows.\n",
        "\n",
        "It may not be ideal for purely categorical data unless categories are encoded numerically first.\n",
        "\n",
        "It is computationally heavier than SimpleImputer, especially for large datasets.\n",
        "\n",
        "Use KNNImputer when:\n",
        "\n",
        "- You believe missing values are related to patterns in other features.\n",
        "\n",
        "- You want a more data-driven imputation than simple mean/median filling.\n",
        "\n",
        "- The dataset is not extremely large (since it can be slow)."
      ],
      "metadata": {
        "id": "0Gxvz0-2HEB9"
      },
      "id": "0Gxvz0-2HEB9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B) Duplicates"
      ],
      "metadata": {
        "id": "d4g5TMbv2P7v"
      },
      "id": "d4g5TMbv2P7v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B1) df.duplicated().sum() — count duplicate rows\n",
        "Duplicates are repeated rows. Counting them helps detect accidental repeats that could bias training."
      ],
      "metadata": {
        "id": "SOManG0N2Vv4"
      },
      "id": "SOManG0N2Vv4"
    },
    {
      "cell_type": "code",
      "source": [
        "# duplicated() returns True for rows that are exact copies of a previous row and False otherwise.\n",
        "#\n",
        "# sum() counts how many True values exist, which gives the total number of duplicate rows.\n",
        "#\n",
        "# Identifying duplicates is important because repeated records\n",
        "# can bias model training and distort evaluation results.\n",
        "\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "OQC2MmKp2a8d"
      },
      "id": "OQC2MmKp2a8d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B2) df.drop_duplicates() — remove duplicates\n",
        "This removes exact duplicate rows. It’s a simple cleanup step before modeling."
      ],
      "metadata": {
        "id": "phxKHPXR2jEw"
      },
      "id": "phxKHPXR2jEw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate rows from the dataset.\n",
        "#\n",
        "# drop_duplicates() removes rows that are exact copies\n",
        "# of earlier rows in the dataset.\n",
        "#\n",
        "# We then compare the original shape with the cleaned shape\n",
        "# to see how many rows were removed.\n",
        "# .shape returns (number_of_rows, number_of_columns).\n",
        "\n",
        "df_no_dupes = df.drop_duplicates()\n",
        "(df.shape, df_no_dupes.shape)\n"
      ],
      "metadata": {
        "id": "8tkFN7vf2nKw"
      },
      "id": "8tkFN7vf2nKw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C) Data type fixes and parsing"
      ],
      "metadata": {
        "id": "QBREAfVu2rR_"
      },
      "id": "QBREAfVu2rR_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C1) Inspect types with df.dtypes\n",
        "Models need the right data types. This shows which columns are numeric vs categorical (object/string)."
      ],
      "metadata": {
        "id": "OPCmkA8I2uL9"
      },
      "id": "OPCmkA8I2uL9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the data type of each column in the dataset.\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "yimWhj3h2z7L"
      },
      "id": "yimWhj3h2z7L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Note**\n",
        "**dtypes** shows whether each column is stored as numeric,categorical (object), integer, float, etc.\n",
        "\n",
        "Understanding data types is important because:\n",
        " - Numeric columns are used for mathematical operations and scaling.\n",
        "- Categorical columns require encoding before modeling.\n",
        "- Incorrect data types can lead to preprocessing errors.\n",
        "\n",
        "This step helps verify that each feature is stored in the expected format before applying transformations."
      ],
      "metadata": {
        "id": "jZ_k1Vc3Ik0O"
      },
      "id": "jZ_k1Vc3Ik0O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C2) pd.to_numeric(..., errors=\"coerce\") — convert messy numeric strings to numbers\n",
        "Sometimes numbers are stored like text (example: \"1,234\"). to_numeric converts them into real numbers. errors=\"coerce\" turns unparseable values into NaN so you can handle them cleanly."
      ],
      "metadata": {
        "id": "FzR9txxZ21_H"
      },
      "id": "FzR9txxZ21_H"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a separate copy of the dataset so the original data remains unchanged.\n",
        "\n",
        "X_parse = X.copy()\n",
        "\n",
        "\n",
        "# Here I am creating a teaching example by converting a numeric column into a messy string format.\n",
        "# Here, LotArea values are converted into strings with comma separators (e.g., 8450 becomes \"8,450\").\n",
        "# This simulates real-world scenarios where numeric data may be stored as text.\n",
        "\n",
        "X_parse[\"LotArea_str\"] = X_parse[\"LotArea\"].map(lambda v: f\"{int(v):,}\")\n",
        "\n",
        "\n",
        "# Convert the messy string column back into a numeric format.\n",
        "\n",
        "X_parse[\"LotArea_parsed\"] = pd.to_numeric(\n",
        "    X_parse[\"LotArea_str\"].str.replace(\",\", \"\"),\n",
        "    errors=\"coerce\"\n",
        ")\n",
        "\n",
        "\n",
        "# Display original numeric values, the messy string version,\n",
        "# and the parsed numeric result to verify the transformation.\n",
        "\n",
        "X_parse[[\"LotArea\", \"LotArea_str\", \"LotArea_parsed\"]].head()\n"
      ],
      "metadata": {
        "id": "3110ipOi26x1"
      },
      "id": "3110ipOi26x1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Note**\n",
        "**str.replace()** is used to modify text inside a string column.\n",
        "In this example: .str.replace(\",\", \"\") - It removes commas from values\n",
        "\n",
        "This step is necessary because commas prevent numeric conversion.\n",
        "Before converting text to numbers, we must clean formatting characters such as:\n",
        "\n",
        "- Commas (,)\n",
        "\n",
        "- Currency symbols ($)\n",
        "\n",
        "- Spaces\n",
        "\n",
        "- Percentage signs (%)\n",
        "\n",
        "The errors parameter controls what happens if a value cannot be converted to a number.\n",
        "- errors=\"raise\" → throws an error (default behavior)\n",
        "\n",
        "- errors=\"coerce\" → converts invalid values to NaN\n",
        "\n",
        "- errors=\"ignore\" → leaves the value unchanged\n",
        "\n",
        "In preprocessing, we usually use: errors=\"coerce\"\n",
        "\n",
        "This is safer because:\n",
        "\n",
        "- It prevents the program from crashing.\n",
        "\n",
        "- Any invalid value becomes NaN.\n",
        "\n",
        "- We can then handle those NaN values using imputation.\n",
        "\n",
        "**You can do the string character replacement and conversion into numeric separately, rather than chaining the functions**"
      ],
      "metadata": {
        "id": "g7VCDOy5LrDY"
      },
      "id": "g7VCDOy5LrDY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C3) pd.to_datetime(...) — parse dates\n",
        "Dates are often strings or integers. Turning them into datetime lets you extract year/month/day and do proper time-based features later."
      ],
      "metadata": {
        "id": "s9E0iUUR2-QP"
      },
      "id": "s9E0iUUR2-QP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a separate copy of the dataset so the original data remains unchanged.\n",
        "\n",
        "X_dates = X.copy()\n",
        "\n",
        "\n",
        "# Create a synthetic date column from the YearBuilt feature.\n",
        "#\n",
        "# Step 1: Convert the YearBuilt values to string format.\n",
        "# Step 2: Append \"-01-01\" so each year becomes a full date (January 1 of that year).\n",
        "# Step 3: Convert the resulting string into a proper datetime object.\n",
        "\n",
        "X_dates[\"BuiltDate\"] = pd.to_datetime(\n",
        "    X_dates[\"YearBuilt\"].astype(str) + \"-01-01\",\n",
        "    errors=\"coerce\"\n",
        ")\n",
        "\n",
        "# Display the original YearBuilt column and the new BuiltDate column to verify the conversion.\n",
        "\n",
        "X_dates[[\"YearBuilt\", \"BuiltDate\"]].head()\n"
      ],
      "metadata": {
        "id": "8LpVBlUK3B_u"
      },
      "id": "8LpVBlUK3B_u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Note**\n",
        "**pd.to_datetime()** converts data into a datetime format that pandas can understand and manipulate. It takes values such as \"2005-01-01\", \"03/15/2010\", \"1998\", and converts them into structured datetime objects.\n",
        "\n",
        "When to_datetime() runs:\n",
        "\n",
        "- It reads the input values (usually strings).\n",
        "\n",
        "- It tries to detect the date format automatically.\n",
        "\n",
        "- It parses the year, month, and day.\n",
        "\n",
        "- It converts the value into a standardized datetime representation.\n",
        "\n",
        "If it cannot interpret a value, behavior depends on the errors parameter.\n"
      ],
      "metadata": {
        "id": "02lhv2XGV85Y"
      },
      "id": "02lhv2XGV85Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C4) astype(\"category\") — convert a column to categorical type\n",
        "This tells pandas “this column is a category, not free-form text.” It can help memory usage and makes the intent clearer."
      ],
      "metadata": {
        "id": "VW_wJTjz3E3Y"
      },
      "id": "VW_wJTjz3E3Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a separate copy of the dataset so the original data remains unchanged.\n",
        "\n",
        "X_cat_type = X.copy()\n",
        "\n",
        "\n",
        "# Convert the \"Neighborhood\" column to categorical type.\n",
        "#\n",
        "# astype(\"category\") tells the dataset that this column\n",
        "# represents discrete categories rather than free-form text.\n",
        "#\n",
        "# This can improve memory efficiency and clearly signals that the feature is categorical in nature.\n",
        "\n",
        "X_cat_type[\"Neighborhood\"] = X_cat_type[\"Neighborhood\"].astype(\"category\")\n",
        "\n",
        "\n",
        "# Display the data type of the column to confirm that it has been converted to a categorical type.\n",
        "\n",
        "X_cat_type[\"Neighborhood\"].dtype\n"
      ],
      "metadata": {
        "id": "QjjO0SXM3IeA"
      },
      "id": "QjjO0SXM3IeA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Note**\n",
        "We pass \"category\" as a string because astype() expects the name of the target data type.\n",
        "\n",
        "In pandas, data types can be specified either:\n",
        "\n",
        "- As built-in Python types (int, float, str)\n",
        "\n",
        "- Or as pandas-recognized type names written as strings (\"category\", \"float64\", etc.)\n",
        "\n",
        "Here, \"category\" tells pandas: “Convert this column into a categorical data type.”\n",
        "\n",
        "When a column is converted to categorical type:\n",
        "\n",
        "- It identifies all unique values in that column.\n",
        "\n",
        "- It stores those unique values as a fixed set of categories.\n",
        "\n",
        "- Internally, it replaces the actual text values with integer codes.\n",
        "\n",
        "- It maintains a mapping between codes and category labels.\n",
        "\n",
        "Converting to \"category\": Does NOT automatically encode it for machine learning. You still need encoding (e.g., OneHotEncoder) before feeding it into most ML models."
      ],
      "metadata": {
        "id": "brWPrNODXZVk"
      },
      "id": "brWPrNODXZVk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C5) .str.strip() — remove extra spaces in strings\n",
        "Extra spaces can create fake categories (like \"NAmes\" vs \"NAmes \"). Stripping whitespace prevents that."
      ],
      "metadata": {
        "id": "t5kEAowR3KAG"
      },
      "id": "t5kEAowR3KAG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a separate copy of the dataset so the original data remains unchanged.\n",
        "\n",
        "X_strip = X.copy()\n",
        "\n",
        "\n",
        "# Teaching example: artificially add extra spaces to the first few rows of the \"MSZoning\" column.\n",
        "#\n",
        "# This simulates real-world messy data where text fields may contain\n",
        "# unintended leading or trailing whitespace.\n",
        "\n",
        "X_strip.loc[X_strip.index[:5], \"MSZoning\"] = (\n",
        "    X_strip.loc[X_strip.index[:5], \"MSZoning\"].astype(str) + \"  \")\n",
        "\n",
        "\n",
        "# Clean the column by removing leading and trailing spaces.\n",
        "#\n",
        "# astype(str) ensures all values are treated as strings.\n",
        "# str.strip() removes whitespace from both ends of each value.\n",
        "#\n",
        "# This prevents duplicate categories caused by hidden spaces\n",
        "# (e.g., \"RL\" vs \"RL  \").\n",
        "\n",
        "X_strip[\"MSZoning\"] = X_strip[\"MSZoning\"].astype(str).str.strip()\n",
        "\n",
        "\n",
        "# Display the first 10 rows to verify that extra spaces have been removed.\n",
        "\n",
        "X_strip[\"MSZoning\"].head(10)\n"
      ],
      "metadata": {
        "id": "G8WKMIsF3Oel"
      },
      "id": "G8WKMIsF3Oel",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C6) .str.lower() — standardize text to lowercase\n",
        "Lowercasing reduces category duplicates caused by capitalization differences (like \"RL\" vs \"rl\")."
      ],
      "metadata": {
        "id": "_Dht42XX3VJg"
      },
      "id": "_Dht42XX3VJg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a separate copy of the dataset so the original data remains unchanged.\n",
        "\n",
        "X_lower = X.copy()\n",
        "\n",
        "\n",
        "# Convert all values in the \"HouseStyle\" column to lowercase.\n",
        "#\n",
        "# astype(str) ensures that all values are treated as strings.\n",
        "# str.lower() converts each value to lowercase.\n",
        "#\n",
        "# This helps standardize categorical text data and prevents\n",
        "# duplicate categories caused by inconsistent capitalization\n",
        "# (e.g., \"TwoStory\" vs \"twostory\").\n",
        "\n",
        "X_lower[\"HouseStyle\"] = X_lower[\"HouseStyle\"].astype(str).str.lower()\n",
        "\n",
        "\n",
        "# Display the first few rows to verify that the text has been converted to lowercase.\n",
        "\n",
        "X_lower[\"HouseStyle\"].head()\n"
      ],
      "metadata": {
        "id": "MdVXBlcy3bN-"
      },
      "id": "MdVXBlcy3bN-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D) Z-score standardization"
      ],
      "metadata": {
        "id": "P9fL_kC83dUe"
      },
      "id": "P9fL_kC83dUe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D1) Manual Z-score: (x - mean) / std\n",
        "Z-score standardization rescales values so they have mean 0 and standard deviation 1. This helps many models (including logistic regression) train more smoothly."
      ],
      "metadata": {
        "id": "iyk55q4X3jgE"
      },
      "id": "iyk55q4X3jgE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a numeric column for demonstration.\n",
        "# Here, we choose \"LotArea\" to manually compute z-score standardization.\n",
        "\n",
        "col = \"LotArea\"\n",
        "\n",
        "\n",
        "# Convert the selected column to float type.\n",
        "# This ensures that mathematical operations can be performed safely.\n",
        "\n",
        "x = X[col].astype(float)\n",
        "\n",
        "\n",
        "# Manually compute the z-score for each value in the column.\n",
        "#\n",
        "# Step 1: x.mean() calculates the average of the column.\n",
        "# Step 2: x.std(ddof=0) calculates the standard deviation.\n",
        "#         ddof=0 means we are using population standard deviation.\n",
        "# Step 3: (x - mean) centers the data around zero.\n",
        "# Step 4: Dividing by standard deviation scales the spread.\n",
        "#\n",
        "# The result is a standardized column with:\n",
        "# - Mean approximately 0\n",
        "# - Standard deviation approximately 1\n",
        "\n",
        "z_manual = (x - x.mean()) / x.std(ddof=0)\n",
        "\n",
        "\n",
        "# Display the first few standardized values.\n",
        "\n",
        "z_manual.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "lkGw02SS3qjA"
      },
      "id": "lkGw02SS3qjA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** You generally do not use manual z-score standardization. You will use the automatic method StandardScaler() as shown below."
      ],
      "metadata": {
        "id": "35IeRyTFZN6D"
      },
      "id": "35IeRyTFZN6D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E) Scalers (fit on train only)\n"
      ],
      "metadata": {
        "id": "35uLo_9O3rfg"
      },
      "id": "35uLo_9O3rfg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E0) Train/test split (common base for scaler demos)\n",
        "We split data into train and test sets. We fit preprocessing on the training set only, then apply it to both sets. This prevents “peeking” at the test set."
      ],
      "metadata": {
        "id": "TZK8dfUL37Xq"
      },
      "id": "TZK8dfUL37Xq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets.\n",
        "#\n",
        "# X contains the input features.\n",
        "# y_reg contains the regression target (SalePrice).\n",
        "#\n",
        "# test_size=0.2 means 20% of the data will be used for testing,\n",
        "# and the remaining 80% will be used for training.\n",
        "#\n",
        "# random_state=42 ensures reproducibility.\n",
        "# This means the split will be the same every time the code runs.\n",
        "#\n",
        "# The function returns:\n",
        "# - X_train: features for training\n",
        "# - X_test:  features for testing\n",
        "# - y_train_reg: target values for training\n",
        "# - y_test_reg:  target values for testing\n",
        "\n",
        "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
        "    X, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Display the shapes of the training and testing feature sets\n",
        "# to confirm the split proportions.\n",
        "\n",
        "(X_train.shape, X_test.shape)\n"
      ],
      "metadata": {
        "id": "E0mTKZas3_Bs"
      },
      "id": "E0mTKZas3_Bs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E1) StandardScaler (fit on train, transform train/test)\n",
        "StandardScaler does z-score standardization automatically. It learns mean/std from training data, then applies the same scaling to test data."
      ],
      "metadata": {
        "id": "B-FUWzl94A25"
      },
      "id": "B-FUWzl94A25"
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify all numeric feature columns.\n",
        "#\n",
        "# select_dtypes(include=[np.number]) selects only numeric columns.\n",
        "# .columns extracts the column names.\n",
        "# .tolist() converts them into a regular Python list so they can be indexed easily.\n",
        "\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Create a StandardScaler object.\n",
        "#\n",
        "# StandardScaler performs z-score standardization automatically\n",
        "#\n",
        "# This is especially useful for models like Linear Regression and Logistic Regression.\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform it.\n",
        "#\n",
        "# IMPORTANT: We fit only on training data to prevent data leakage.\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
        "\n",
        "\n",
        "# Transform the test data using the same scaling parameters learned from the training data.\n",
        "# We do NOT call fit() on the test data.\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test[num_cols])\n",
        "\n",
        "\n",
        "# Convert the scaled NumPy array back into a DataFrame and restore the column names for readability.\n",
        "\n",
        "pd.DataFrame(X_train_scaled, columns=num_cols).head()\n"
      ],
      "metadata": {
        "id": "7Qt4bjsQ4INX"
      },
      "id": "7Qt4bjsQ4INX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E2) MinMaxScaler\n",
        "MinMaxScaler squeezes values into a fixed range (usually 0 to 1). It’s useful when you want all numeric features on the same bounded scale."
      ],
      "metadata": {
        "id": "P6LImgNc4J_n"
      },
      "id": "P6LImgNc4J_n"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a MinMaxScaler object.\n",
        "#\n",
        "# MinMaxScaler rescales numeric features to a fixed range, typically between 0 and 1.\n",
        "#\n",
        "# Formula:\n",
        "# (value - min) / (max - min)\n",
        "#\n",
        "# This preserves the shape of the distribution but changes the scale of the values.\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "\n",
        "# Fit the scaler on the training data and transform it.\n",
        "#\n",
        "# We fit only on training data to avoid data leakage.\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
        "\n",
        "\n",
        "# Transform the test data using the same learned min/max values.\n",
        "# We do NOT fit again on the test data.\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test[num_cols])\n",
        "\n",
        "\n",
        "# Convert the scaled NumPy array back into a DataFrame and restore column names for readability.\n",
        "\n",
        "pd.DataFrame(X_train_scaled, columns=num_cols).head()\n"
      ],
      "metadata": {
        "id": "fLbxEyIv4YRw"
      },
      "id": "fLbxEyIv4YRw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E3) RobustScaler\n",
        "RobustScaler uses median and IQR instead of mean/std, so it’s less sensitive to outliers (extreme values)."
      ],
      "metadata": {
        "id": "Bbde84Bf4bhZ"
      },
      "id": "Bbde84Bf4bhZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a RobustScaler object.\n",
        "#\n",
        "# RobustScaler scales features using the median and the interquartile range (IQR),\n",
        "# instead of the mean and standard deviation.\n",
        "#\n",
        "# Formula conceptually:\n",
        "# (value - median) / IQR\n",
        "#\n",
        "# This makes it less sensitive to extreme values (outliers) compared to StandardScaler.\n",
        "\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform it.\n",
        "#\n",
        "# Fitting only on training data prevents data leakage.\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
        "\n",
        "# Transform the test data using the same median and IQR learned from the training data.\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test[num_cols])\n",
        "\n",
        "# Convert the scaled NumPy array back into a DataFrame and restore the column names for clarity.\n",
        "\n",
        "pd.DataFrame(X_train_scaled, columns=num_cols).head()\n"
      ],
      "metadata": {
        "id": "NMeboKjM4jFv"
      },
      "id": "NMeboKjM4jFv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E4) MaxAbsScaler\n",
        "MaxAbsScaler scales each feature by its maximum absolute value. It’s often used when working with sparse data, but still useful to know."
      ],
      "metadata": {
        "id": "ULsn9XK27RTE"
      },
      "id": "ULsn9XK27RTE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a MaxAbsScaler object.\n",
        "#\n",
        "# MaxAbsScaler scales each numeric feature by dividing\n",
        "# by its maximum absolute value.\n",
        "#\n",
        "# Formula conceptually:\n",
        "# value / max(|value|)\n",
        "#\n",
        "# This rescales features into the range [-1, 1] while preserving zero values and sparsity.\n",
        "#\n",
        "# It is especially useful for sparse data, but can also be applied to general numeric features.\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "\n",
        "\n",
        "# Fit the scaler on the training data and transform it.\n",
        "#\n",
        "# Fitting only on training data prevents data leakage.\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
        "\n",
        "\n",
        "# Transform the test data using the same scaling parameters learned from the training data.\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test[num_cols])\n",
        "\n",
        "# Convert the scaled NumPy array back into a DataFrame and restore the column names for readability.\n",
        "\n",
        "pd.DataFrame(X_train_scaled, columns=num_cols).head()\n"
      ],
      "metadata": {
        "id": "8KQW20H57VM6"
      },
      "id": "8KQW20H57VM6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E5) Normalizer\n",
        "Normalizer scales each row (each sample) so the row length becomes 1. This is more common in text/vector problems, but it’s good to understand what it does."
      ],
      "metadata": {
        "id": "sprJ6VNA7W8e"
      },
      "id": "sprJ6VNA7W8e"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Normalizer object.\n",
        "#\n",
        "# Normalizer rescales each individual row (sample), not each column (feature).\n",
        "#\n",
        "# It adjusts the values in a row so that the entire row has a unit length (magnitude = 1).\n",
        "#\n",
        "# This is commonly used in vector-based data\n",
        "# (e.g., text features), but can be applied to numeric data as well.\n",
        "\n",
        "normalizer = Normalizer()\n",
        "\n",
        "\n",
        "# Replace missing values with 0 before normalization.\n",
        "#\n",
        "# Normalizer cannot handle missing values,\n",
        "# so we temporarily fill them with 0 to allow computation.\n",
        "\n",
        "X_train_norm = normalizer.fit_transform(X_train[num_cols].fillna(0))\n",
        "\n",
        "\n",
        "# Transform the test data using the same normalization rule.\n",
        "# Unlike scalers, Normalizer does not learn statistics like mean or min/max.\n",
        "# It simply rescales each row independently.\n",
        "\n",
        "X_test_norm = normalizer.transform(X_test[num_cols].fillna(0))\n",
        "\n",
        "\n",
        "# Convert the normalized NumPy array back into a DataFrame\n",
        "# and restore column names for readability.\n",
        "\n",
        "pd.DataFrame(X_train_norm, columns=num_cols).head()\n"
      ],
      "metadata": {
        "id": "dAdWBh8Z7a52"
      },
      "id": "dAdWBh8Z7a52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F) Categorical encoding"
      ],
      "metadata": {
        "id": "TZqD4UiY7ctM"
      },
      "id": "TZqD4UiY7ctM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F1) pd.get_dummies(..., drop_first=True)\n",
        "One-hot encoding turns categories into 0/1 columns. drop_first=True avoids creating redundant columns (helps reduce collinearity)."
      ],
      "metadata": {
        "id": "JbGUMNnc7fgt"
      },
      "id": "JbGUMNnc7fgt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply one-hot encoding to categorical columns using pandas.\n",
        "#\n",
        "# pd.get_dummies() converts categorical variables into binary (0/1) columns.\n",
        "# For each unique category in a column, a new column is created.\n",
        "#\n",
        "# columns=cat_cols specifies which columns should be encoded.\n",
        "# Only the categorical columns are transformed.\n",
        "#\n",
        "# drop_first=True removes the first category from each encoded feature.\n",
        "# This helps prevent multicollinearity (also known as the dummy variable trap),\n",
        "# which is especially important for Linear and Logistic Regression.\n",
        "#\n",
        "# The result is a new DataFrame where categorical features\n",
        "# are replaced with numeric 0/1 indicator columns.\n",
        "\n",
        "X_dummies = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
        "\n",
        "\n",
        "# Display the first few rows to observe the new encoded structure.\n",
        "\n",
        "X_dummies.head()\n"
      ],
      "metadata": {
        "id": "cNeLSG-f7mNa"
      },
      "id": "cNeLSG-f7mNa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F2) OneHotEncoder(handle_unknown=\"ignore\")\n",
        "This is the scikit-learn version of one-hot encoding. handle_unknown=\"ignore\" prevents errors if the test set has a category never seen in training."
      ],
      "metadata": {
        "id": "kFVfB9A97vAX"
      },
      "id": "kFVfB9A97vAX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a OneHotEncoder object.\n",
        "#\n",
        "# OneHotEncoder converts categorical variables into binary (0/1) columns,\n",
        "# similar to pd.get_dummies(), but designed for use in machine learning pipelines.\n",
        "#\n",
        "# handle_unknown=\"ignore\" ensures that if new categories appear in future data (e.g., test set or production),\n",
        "# the encoder will not raise an error.\n",
        "#\n",
        "# sparse_output=False returns a dense NumPy array instead of a sparse matrix,\n",
        "# making it easier to view and convert into a DataFrame for demonstration.\n",
        "\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "\n",
        "# Fit the encoder on the categorical columns and transform them.\n",
        "#\n",
        "# NOTE: Here we fit on the full dataset only for demonstration purposes.\n",
        "# In real machine learning workflows, we should fit only on training data to avoid data leakage.\n",
        "\n",
        "X_ohe = ohe.fit_transform(X[cat_cols])\n",
        "\n",
        "\n",
        "# Convert the encoded NumPy array into a DataFrame.\n",
        "#\n",
        "# get_feature_names_out() retrieves the generated column names\n",
        "# (e.g., Neighborhood_CollgCr, HouseStyle_2Story, etc.)\n",
        "# so the output is interpretable.\n",
        "\n",
        "pd.DataFrame(X_ohe, columns=ohe.get_feature_names_out(cat_cols)).head()\n"
      ],
      "metadata": {
        "id": "QjYhrb3O7zfs"
      },
      "id": "QjYhrb3O7zfs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F3) OrdinalEncoder with unknown handling\n",
        "Ordinal encoding replaces categories with integers (e.g., “A”→0, “B”→1). It’s compact, but the model may assume an order that doesn’t really exist—so use it carefully."
      ],
      "metadata": {
        "id": "WQxo_Vuo71nz"
      },
      "id": "WQxo_Vuo71nz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an OrdinalEncoder object.\n",
        "#\n",
        "# OrdinalEncoder converts each category into an integer value.\n",
        "#\n",
        "# handle_unknown=\"use_encoded_value\" ensures that if a new, previously unseen category\n",
        "# appears during transformation, the encoder will not raise an error.\n",
        "#\n",
        "# unknown_value=-1 assigns the value -1 to any unseen category.\n",
        "# This prevents failures during inference on new data.\n",
        "\n",
        "ord_enc = OrdinalEncoder(\n",
        "    handle_unknown=\"use_encoded_value\",\n",
        "    unknown_value=-1)\n",
        "\n",
        "# Fit the encoder on the categorical columns and transform them.\n",
        "#\n",
        "# Unlike one-hot encoding, this produces one numeric column per feature.\n",
        "\n",
        "X_ord = ord_enc.fit_transform(X[cat_cols])\n",
        "\n",
        "\n",
        "# Convert the encoded NumPy array back into a DataFrame\n",
        "# and restore the original column names for readability.\n",
        "\n",
        "pd.DataFrame(X_ord, columns=cat_cols).head()\n"
      ],
      "metadata": {
        "id": "e6IanyqT76AN"
      },
      "id": "e6IanyqT76AN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# G) Train/test split + fit only on train\n"
      ],
      "metadata": {
        "id": "3XqSr5By77yH"
      },
      "id": "3XqSr5By77yH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# G1) train_test_split(..., random_state=...) for regression\n",
        "This creates a repeatable split (same result every run). Great for consistent demos and debugging."
      ],
      "metadata": {
        "id": "Z1Vschz57-4S"
      },
      "id": "Z1Vschz57-4S"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
        "    X, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "(X_train_r.shape, X_test_r.shape)"
      ],
      "metadata": {
        "id": "ZwJeIQSZ8HgZ"
      },
      "id": "ZwJeIQSZ8HgZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# G2) train_test_split(..., stratify=y) for classification\n",
        "Stratification keeps the class balance similar in train and test. This is important when classes are imbalanced."
      ],
      "metadata": {
        "id": "VROx5mQd8JUD"
      },
      "id": "VROx5mQd8JUD"
    },
    {
      "cell_type": "code",
      "source": [
        "# stratify=y_clf ensures that the class distribution\n",
        "# (proportion of 0s and 1s) remains similar in both the training and test sets.\n",
        "# This is especially important for classification tasks, particularly when classes are imbalanced.\n",
        "\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
        "    X, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
        ")\n",
        "\n",
        "# Compute the mean of the binary target in both sets.\n",
        "#\n",
        "# Since the target is 0 and 1, the mean represents the proportion of class 1 (HighPrice).\n",
        "#\n",
        "# Similar values confirm that stratification worked correctly.\n",
        "\n",
        "(y_train_c.mean(), y_test_c.mean())"
      ],
      "metadata": {
        "id": "Q2K9wbCG8Muf"
      },
      "id": "Q2K9wbCG8Muf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# G3) Fit transformer on train only (example: imputer)\n",
        "We learn imputation values from the training set only. Then we apply the same learned values to the test set. This prevents test information from influencing training."
      ],
      "metadata": {
        "id": "eQZtyTCh8OoB"
      },
      "id": "eQZtyTCh8OoB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SimpleImputer with strategy=\"median\".\n",
        "#\n",
        "# This means missing values in numeric columns\n",
        "# will be replaced with the median (middle value) of each column.\n",
        "\n",
        "imp = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "\n",
        "# Fit the imputer on the training data and transform it.\n",
        "#\n",
        "# Fitting only on training data prevents data leakage.\n",
        "\n",
        "X_train_num_imp = imp.fit_transform(X_train_r[num_cols])\n",
        "\n",
        "\n",
        "# Apply the same learned medians to the test data.\n",
        "# We do NOT call fit() again on the test set.\n",
        "\n",
        "X_test_num_imp = imp.transform(X_test_r[num_cols])\n",
        "\n",
        "\n",
        "# Convert the imputed NumPy array back into a DataFrame\n",
        "# and restore the original column names for readability.\n",
        "\n",
        "pd.DataFrame(X_train_num_imp, columns=num_cols).head()\n"
      ],
      "metadata": {
        "id": "iZI2HpeN8Soy"
      },
      "id": "iZI2HpeN8Soy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# G4) Fit transformer on train only (example: scaler)\n",
        "Scaling must be fit on training data only. Otherwise, the test set influences the scaling parameters (data leakage)."
      ],
      "metadata": {
        "id": "8annrWTK8UX4"
      },
      "id": "8annrWTK8UX4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler object.\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "# Replace missing values with 0 temporarily before scaling.\n",
        "#\n",
        "# StandardScaler cannot handle missing values directly,\n",
        "# so we fill them here to allow the transformation.\n",
        "# (In practice, imputation should ideally be done separately\n",
        "# before scaling using a proper imputer.)\n",
        "\n",
        "X_train_num_scaled = scaler.fit_transform(X_train_r[num_cols].fillna(0))\n",
        "\n",
        "\n",
        "# Transform the test data using the same scaling parameters learned from the training data.\n",
        "# We do NOT call fit() on the test data to prevent data leakage.\n",
        "\n",
        "X_test_num_scaled = scaler.transform(X_test_r[num_cols].fillna(0))\n",
        "\n",
        "\n",
        "# Convert the scaled NumPy array back into a DataFrame\n",
        "# and restore the original column names for readability.\n",
        "\n",
        "pd.DataFrame(X_train_num_scaled, columns=num_cols).head()\n"
      ],
      "metadata": {
        "id": "U34jtY-68ZUD"
      },
      "id": "U34jtY-68ZUD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H) Prebuilt sklearn workflow building blocks"
      ],
      "metadata": {
        "id": "xPUoXmQ58bpP"
      },
      "id": "xPUoXmQ58bpP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H1) ColumnTransformer (numeric pipeline + categorical pipeline)\n",
        "Different columns need different preprocessing: numbers get imputed + scaled, categories get imputed + one-hot encoded. ColumnTransformer applies the right steps to the right columns."
      ],
      "metadata": {
        "id": "SVNqydKK8gYp"
      },
      "id": "SVNqydKK8gYp"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of numeric and categorical features.\n",
        "#\n",
        "# This separation allows us to apply different preprocessing steps to different types of data.\n",
        "\n",
        "numeric_features = num_cols\n",
        "categorical_features = cat_cols.tolist()\n",
        "\n",
        "\n",
        "# Create a preprocessing pipeline for numeric features.\n",
        "#\n",
        "# Step 1: Impute missing values using the median.\n",
        "# Step 2: Scale the features using StandardScaler.\n",
        "#\n",
        "# These steps will be applied sequentially to numeric columns.\n",
        "\n",
        "numeric_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "\n",
        "# Create a preprocessing pipeline for categorical features.\n",
        "#\n",
        "# Step 1: Impute missing values using the most frequent category.\n",
        "# Step 2: Apply one-hot encoding to convert categories into 0/1 columns.\n",
        "\n",
        "categorical_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "\n",
        "# Combine both pipelines using ColumnTransformer.\n",
        "#\n",
        "# (\"num\", numeric_pipe, numeric_features)\n",
        "#   → Apply the numeric pipeline to numeric columns.\n",
        "#\n",
        "# (\"cat\", categorical_pipe, categorical_features)\n",
        "#   → Apply the categorical pipeline to categorical columns.\n",
        "#\n",
        "# remainder=\"drop\" ensures that any columns not specified\n",
        "# are removed from the output.\n",
        "#\n",
        "# This creates a single preprocessing object\n",
        "# that can handle mixed data types automatically.\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_pipe, numeric_features),\n",
        "        (\"cat\", categorical_pipe, categorical_features)\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "\n",
        "# Display the full preprocessing configuration.\n",
        "\n",
        "preprocess\n",
        "\n"
      ],
      "metadata": {
        "id": "-CWyBqT_8mCh"
      },
      "id": "-CWyBqT_8mCh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Note**\n",
        "A **Pipeline** chains multiple preprocessing steps (and optionally a model) into a single object.\n",
        "\n",
        "It ensures that:\n",
        "\n",
        "- Steps run in order\n",
        "\n",
        "- The same transformations are applied consistently\n",
        "\n",
        "- There is no data leakage\n",
        "\n",
        "- Code stays clean and reusable\n",
        "\n",
        "**ColumnTransformer** applies different preprocessing pipelines to different columns.\n",
        "\n",
        "**Pipeline** = sequential steps\n",
        "\n",
        "**ColumnTransformer** = parallel processing of column groups\n",
        "\n",
        "Together they create a structured preprocessing system.\n",
        "\n",
        "You only need **ColumnTransformer** when: You have different types of columns and they need different preprocessing steps\n",
        "\n",
        "**Important:** Defining Pipeline or ColumnTransformer does NOT process data.\n",
        "It only sets up the structure."
      ],
      "metadata": {
        "id": "0BWBGxKRsOg8"
      },
      "id": "0BWBGxKRsOg8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H2) Full Pipeline: preprocessing + LinearRegression\n",
        "A pipeline bundles preprocessing and modeling together. It ensures the same preprocessing is applied consistently, and it prevents leakage because the pipeline is fit only on training data."
      ],
      "metadata": {
        "id": "oVufOxhO86bz"
      },
      "id": "oVufOxhO86bz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a full pipeline that combines preprocessing and the model.\n",
        "#\n",
        "# Step 1: \"preprocess\" applies all transformations defined earlier\n",
        "#         (imputation, scaling, encoding).\n",
        "# Step 2: \"model\" applies LinearRegression to the transformed data.\n",
        "#\n",
        "# This ensures that preprocessing and modeling are executed\n",
        "# sequentially and consistently.\n",
        "\n",
        "lin_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"model\", LinearRegression())\n",
        "])\n",
        "\n",
        "\n",
        "# Fit the entire pipeline on the training data.\n",
        "#\n",
        "# During fit():\n",
        "# 1. The preprocessing steps learn required statistics from X_train_r\n",
        "#    (e.g., medians, scaling parameters, category mappings).\n",
        "# 2. The transformed data is passed to the LinearRegression model.\n",
        "# 3. The model learns relationships between features and y_train_r.\n",
        "\n",
        "lin_pipe.fit(X_train_r, y_train_r)\n",
        "\n",
        "\n",
        "# Generate predictions on the test data.\n",
        "#\n",
        "# During predict():\n",
        "# 1. The test data is transformed using the SAME preprocessing rules\n",
        "#    learned from training data.\n",
        "# 2. The trained model makes predictions on the transformed test data.\n",
        "\n",
        "y_pred = lin_pipe.predict(X_test_r)\n",
        "\n",
        "\n",
        "# Evaluate model performance.\n",
        "#\n",
        "# R^2 measures how much variance in the target is explained by the model (higher is better).\n",
        "#\n",
        "# RMSE (Root Mean Squared Error) measures the average prediction error in the same units as the target.\n",
        "# Lower RMSE indicates better performance.\n",
        "\n",
        "print(\"R^2:\", r2_score(y_test_r, y_pred))\n",
        "print(\"RMSE:\", mean_squared_error(y_test_r, y_pred, squared=False))\n"
      ],
      "metadata": {
        "id": "OuCM-ktI8-BK"
      },
      "id": "OuCM-ktI8-BK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H3) Full Pipeline: preprocessing + LogisticRegression\n",
        "Logistic regression is sensitive to scaling, so the numeric scaling inside the pipeline is especially helpful. This pipeline handles missing values, encoding, and scaling automatically."
      ],
      "metadata": {
        "id": "vXM12u-O9Cwy"
      },
      "id": "vXM12u-O9Cwy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a full pipeline that combines preprocessing and Logistic Regression.\n",
        "#\n",
        "# Step 1: \"preprocess\" applies all transformations\n",
        "#         (imputation, scaling, encoding).\n",
        "# Step 2: \"model\" applies LogisticRegression for binary classification.\n",
        "#\n",
        "# max_iter=2000 increases the maximum number of iterations\n",
        "# allowed for the optimization algorithm to converge.\n",
        "# This is helpful when working with scaled and encoded data.\n",
        "\n",
        "log_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"model\", LogisticRegression(max_iter=2000))\n",
        "])\n",
        "\n",
        "\n",
        "# Fit the entire pipeline on the training data.\n",
        "#\n",
        "# During fit():\n",
        "# 1. Preprocessing steps learn parameters from X_train_c.\n",
        "# 2. The transformed training data is passed to the Logistic Regression model.\n",
        "# 3. The model learns how features relate to the binary target y_train_c.\n",
        "\n",
        "log_pipe.fit(X_train_c, y_train_c)\n",
        "\n",
        "\n",
        "# Generate predictions on the test data.\n",
        "#\n",
        "# During predict():\n",
        "# 1. The test data is transformed using the SAME preprocessing rules.\n",
        "# 2. The trained logistic model outputs predicted class labels (0 or 1).\n",
        "\n",
        "y_pred = log_pipe.predict(X_test_c)\n",
        "\n",
        "\n",
        "# Evaluate classification performance.\n",
        "#\n",
        "# Accuracy measures the proportion of correct predictions.\n",
        "#\n",
        "# classification_report provides detailed metrics:\n",
        "# - Precision\n",
        "# - Recall\n",
        "# - F1-score\n",
        "# - Support (number of samples per class)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test_c, y_pred))\n",
        "print(classification_report(y_test_c, y_pred))\n"
      ],
      "metadata": {
        "id": "xtOmxfD09IpE"
      },
      "id": "xtOmxfD09IpE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I) Saving artifacts\n"
      ],
      "metadata": {
        "id": "HWGK-0c59Kx9"
      },
      "id": "HWGK-0c59Kx9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I1) joblib.dump(...) — save the trained pipeline\n",
        "Saving lets you reuse the exact same preprocessing + model later without retraining. This is how real ML systems stay consistent in production."
      ],
      "metadata": {
        "id": "gvU2ttWM9Ore"
      },
      "id": "gvU2ttWM9Ore"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained pipelines to disk.\n",
        "#\n",
        "# joblib.dump() serializes (saves) the entire pipeline object,\n",
        "# including:\n",
        "# - All preprocessing steps (imputers, scalers, encoders)\n",
        "# - The trained machine learning model\n",
        "# - All learned parameters\n",
        "#\n",
        "# This allows the exact same pipeline to be loaded later\n",
        "# for prediction without retraining.\n",
        "#\n",
        "# The file extension \".joblib\" is commonly used for saved\n",
        "# scikit-learn models and preprocessing objects.\n",
        "\n",
        "joblib.dump(log_pipe, \"logistic_preprocess_pipeline.joblib\")\n",
        "joblib.dump(lin_pipe, \"linear_preprocess_pipeline.joblib\")\n",
        "\n",
        "print(\"Saved pipelines to disk.\")\n"
      ],
      "metadata": {
        "id": "eD1iYAKK9S52"
      },
      "id": "eD1iYAKK9S52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The file is saved in the current working directory (usually the same folder where your notebook is running).\n",
        "\n",
        "If you want it to be saved in a particular directory, follow the method below."
      ],
      "metadata": {
        "id": "mRpMVQV0x6Jx"
      },
      "id": "mRpMVQV0x6Jx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Path to save it in another directory if required\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "model_dir = Path(\"/content/drive/MyDrive/ML\")\n",
        "\n",
        "# Define full paths\n",
        "log_path = model_dir / \"logistic_preprocess_pipeline.joblib\"\n",
        "lin_path = model_dir / \"linear_preprocess_pipeline.joblib\"\n",
        "\n",
        "# Save models\n",
        "joblib.dump(log_pipe, log_path)\n",
        "joblib.dump(lin_pipe, lin_path)\n",
        "\n",
        "print(\"Saved pipelines to:\", model_dir.resolve())\n"
      ],
      "metadata": {
        "id": "JdgVqRZpyEfS"
      },
      "id": "JdgVqRZpyEfS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I2) joblib.load(...) — load the pipeline and predict again\n",
        "Loading proves your preprocessing and model can be reused exactly as-is. This is essential for deployment and reproducibility."
      ],
      "metadata": {
        "id": "0VFGUaZt9WHB"
      },
      "id": "0VFGUaZt9WHB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the previously saved pipeline objects from disk.\n",
        "#\n",
        "# joblib.load() reads the serialized pipeline file\n",
        "# and restores the entire object exactly as it was saved,\n",
        "# including:\n",
        "# - Preprocessing steps\n",
        "# - Learned parameters\n",
        "# - Trained model weights\n",
        "\n",
        "loaded_log_pipe = joblib.load(\"logistic_preprocess_pipeline.joblib\")\n",
        "loaded_lin_pipe = joblib.load(\"linear_preprocess_pipeline.joblib\")\n",
        "\n",
        "\n",
        "# Use the loaded pipelines to make predictions.\n",
        "#\n",
        "# Even though we only provide raw feature data (X_test),\n",
        "# the pipeline automatically:\n",
        "# 1. Applies preprocessing (imputation, scaling, encoding)\n",
        "# 2. Passes the transformed data into the trained model\n",
        "# 3. Returns predictions\n",
        "#\n",
        "# This demonstrates that the saved pipeline\n",
        "# preserves the entire preprocessing + modeling workflow.\n",
        "\n",
        "print(\"Logistic predictions (first 5):\", loaded_log_pipe.predict(X_test_c.head()))\n",
        "print(\"Linear predictions (first 5):\", loaded_lin_pipe.predict(X_test_r.head()))\n"
      ],
      "metadata": {
        "id": "NZ90_SfF9bPh"
      },
      "id": "NZ90_SfF9bPh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8vYxKiid9etX"
      },
      "id": "8vYxKiid9etX"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}